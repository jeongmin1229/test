사실상 버트는 단순히 숫자를 벡터화 해주는 것 ?? 

Seq to seq
인코더 : 입력 시퀀스를 이해해서 벡터화 해주는 것 
파인튜닝 : 입력 시퀀스를 가지고 요약문을 매핑하는 것 

여기서 classfier은 디코더인 부분

통으로 넣었는데 성능이 안 좋으면 또 쪼개서... 

그럼 디코더 부분에는 어떤 것을 사용해야 하나?? Attention을 써야하나???

디코더의 입력과 정답이 매핑되게 

인코더와 디코더도 하나의 모델이라고 생각하면 된다

Self attention 과 mark attention